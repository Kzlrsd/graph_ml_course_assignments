{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aduqhYLMc3Kk",
        "outputId": "ba3c424c-8b86-44f0-f90b-e460d3a794b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.htm\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ],
      "source": [
        "pip install  dgl -f https://data.dgl.ai/wheels/repo.htm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFvZE-QgdJjV",
        "outputId": "da3b7387-3212-4e69-a739-761604da5299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=40553204251c028d77fdeafdb19ee669e87f86cc55aea01f5cabd58f0a740575\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O2-fyNPdQFO"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p05SYkqOdenG",
        "outputId": "85bca7ed-69d6-4ee0-f69a-56c988389766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWSQGDmGdsn3"
      },
      "outputs": [],
      "source": [
        "current_dir = \"/content/gdrive/MyDrive/graph_data.zip\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd0wu-O1dwzb"
      },
      "outputs": [],
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=True, scaler=None , scaler_regression=None):\n",
        "            self.train = train\n",
        "            self.scaler = scaler\n",
        "            self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "            num_graphs = len(self.data_set)\n",
        "            self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "            self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "            self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "            self.transform = transform\n",
        "            self.scaler_regression = scaler_regression\n",
        "\n",
        "    def scaler_method(self):\n",
        "        if self.train:\n",
        "            scaler = preprocessing.StandardScaler().fit(self.labels)\n",
        "            return scaler\n",
        "        else:\n",
        "            return None\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "    def __getitem__(self, idx):\n",
        "        if self.scaler_regression:\n",
        "            \"\"\" With Scaler\"\"\"\n",
        "            return  self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]\n",
        "        else:\n",
        "            \"\"\" Without Scaler \"\"\"\n",
        "            return  self.data_set[idx], self.labels[idx].float(), self.masks[idx], self.globals[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBd6_Y3YeIB1",
        "outputId": "32c8fa9b-36e6-455d-eb45-231cb15fe1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "513 64 65\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetReg(address=path_data_temp+\"_train\")\n",
        "scaler.fit(train_set.scaler_method().transform(train_set.labels))\n",
        "val_set = DGLDatasetReg(address=path_data_temp+\"_val\", scaler=scaler)\n",
        "test_set= DGLDatasetReg(address=path_data_temp+\"_test\", scaler=scaler)\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_3frJMheRM9"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzhR6uyqeavl"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnqL5QxLemfh"
      },
      "outputs": [],
      "source": [
        "#freesol dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5CG0lxZeoIV"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree = True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree = True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_zazBWgeuaq"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "            for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "                prediction = model(mol_dgl_graph, globals)\n",
        "                prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "                labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "                loss = loss_sum(prediction, labels)\n",
        "                final_loss += loss.item()\n",
        "            final_loss /= val_size\n",
        "            final_loss = math.sqrt(final_loss) # RMSE\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5zFM4BfNhgcC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGrGnQABe0Dw"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XSD1UyOe5QE"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQCbVtyCe-Wa"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = math.inf\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5eWsK23fbqI"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA6H0G7hfjat",
        "outputId": "28a440f2-0834-4245-a926-a6ff17400937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 25.764 | Valid Score: 6.905\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 6.905 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 25.915 | Valid Score: 6.767\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 6.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 23.253 | Valid Score: 6.627\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 6.627 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 22.044 | Valid Score: 6.486\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 6.486 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 20.959 | Valid Score: 6.336\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 6.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 19.719 | Valid Score: 6.180\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 6.180 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 18.540 | Valid Score: 6.008\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 6.008 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 17.380 | Valid Score: 5.835\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 5.835 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 16.273 | Valid Score: 5.664\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 5.664 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 15.535 | Valid Score: 5.490\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 5.490 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 14.742 | Valid Score: 5.321\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 5.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 13.856 | Valid Score: 5.172\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 5.172 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 13.102 | Valid Score: 5.036\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 5.036 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 12.657 | Valid Score: 4.911\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 4.911 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 12.287 | Valid Score: 4.798\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 4.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 11.915 | Valid Score: 4.687\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 4.687 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 11.766 | Valid Score: 4.607\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 4.607 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 11.504 | Valid Score: 4.539\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 4.539 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 11.449 | Valid Score: 4.469\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 4.469 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 11.167 | Valid Score: 4.424\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 4.424 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 11.067 | Valid Score: 4.376\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 4.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 11.285 | Valid Score: 4.339\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 4.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 10.937 | Valid Score: 4.325\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 4.325 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 11.050 | Valid Score: 4.303\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 4.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 10.774 | Valid Score: 4.273\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 4.273 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 10.682 | Valid Score: 4.259\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 4.259 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 10.592 | Valid Score: 4.224\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 4.224 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 10.548 | Valid Score: 4.211\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 4.211 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 10.448 | Valid Score: 4.202\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 4.202 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 10.604 | Valid Score: 4.178\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 4.178 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 11.062 | Valid Score: 4.154\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 4.154 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 10.307 | Valid Score: 4.180\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 4.154 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 33/100 | Training Loss: 10.201 | Valid Score: 4.164\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 4.154 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 10.456 | Valid Score: 4.141\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 4.141 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 10.161 | Valid Score: 4.119\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 4.119 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 10.048 | Valid Score: 4.096\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 4.096 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 10.080 | Valid Score: 4.089\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 4.089 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 9.908 | Valid Score: 4.075\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 4.075 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 9.893 | Valid Score: 4.069\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 4.069 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 9.781 | Valid Score: 4.060\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 4.060 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 10.660 | Valid Score: 4.060\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 4.060 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 9.682 | Valid Score: 4.021\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 4.021 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 9.600 | Valid Score: 4.021\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 4.021 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 9.638 | Valid Score: 4.017\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 4.017 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 9.524 | Valid Score: 4.006\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 4.006 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 9.443 | Valid Score: 4.003\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 4.003 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 9.390 | Valid Score: 3.996\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.996 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 9.866 | Valid Score: 3.986\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.986 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 9.261 | Valid Score: 3.991\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.986 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 9.215 | Valid Score: 3.985\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.985 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 9.216 | Valid Score: 3.964\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.964 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 9.404 | Valid Score: 3.966\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.964 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 9.227 | Valid Score: 3.935\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.935 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 9.179 | Valid Score: 3.930\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.930 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 9.027 | Valid Score: 3.921\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.921 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 8.900 | Valid Score: 3.929\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.921 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 9.155 | Valid Score: 3.907\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.907 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 9.219 | Valid Score: 3.887\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.887 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 8.767 | Valid Score: 3.912\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.887 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 8.716 | Valid Score: 3.892\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 3.887 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 8.993 | Valid Score: 3.883\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 3.883 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 11.009 | Valid Score: 3.857\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 3.857 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 8.621 | Valid Score: 3.827\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 8.524 | Valid Score: 3.842\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 65/100 | Training Loss: 8.502 | Valid Score: 3.845\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 66/100 | Training Loss: 8.400 | Valid Score: 3.845\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 67/100 | Training Loss: 8.400 | Valid Score: 3.839\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 68/100 | Training Loss: 8.340 | Valid Score: 3.835\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 3.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 8.272 | Valid Score: 3.823\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 3.823 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 8.240 | Valid Score: 3.828\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 3.823 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 8.229 | Valid Score: 3.815\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 3.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 8.141 | Valid Score: 3.823\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 3.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 8.098 | Valid Score: 3.815\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 3.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 9.215 | Valid Score: 3.815\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 3.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 8.236 | Valid Score: 3.805\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 3.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 8.029 | Valid Score: 3.797\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 3.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 7.924 | Valid Score: 3.791\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 3.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 7.917 | Valid Score: 3.790\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 3.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 8.051 | Valid Score: 3.773\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 3.773 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 8.127 | Valid Score: 3.791\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 3.773 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 7.790 | Valid Score: 3.764\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 3.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 7.695 | Valid Score: 3.762\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 3.762 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 8.086 | Valid Score: 3.763\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 3.762 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 7.821 | Valid Score: 3.771\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 3.762 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 7.818 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 7.534 | Valid Score: 3.767\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 87/100 | Training Loss: 7.533 | Valid Score: 3.760\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 88/100 | Training Loss: 7.475 | Valid Score: 3.759\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 7.411 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 3.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 7.380 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 3.752 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 7.520 | Valid Score: 3.745\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 3.745 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 7.476 | Valid Score: 3.732\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 3.732 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 7.292 | Valid Score: 3.721\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 7.244 | Valid Score: 3.733\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 7.213 | Valid Score: 3.734\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 96/100 | Training Loss: 7.163 | Valid Score: 3.731\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 97/100 | Training Loss: 7.744 | Valid Score: 3.728\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 3.721 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 7.115 | Valid Score: 3.720\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 3.720 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 7.023 | Valid Score: 3.722\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 3.720 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 100/100 | Training Loss: 7.084 | Valid Score: 3.720\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 3.720 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.720 \n",
            "\n",
            "Test Score: 3.358 \n",
            "\n",
            "Execution time: 61.885 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YZV7QAig-e_"
      },
      "outputs": [],
      "source": [
        "import dgl.function as fn\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size, aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size , aggregator_type='mean')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXe2Ohzldxp",
        "outputId": "af6c0717-71ed-455e-843c-240e0260dd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 22.653 | Valid Score: 6.584\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 6.584 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 21.591 | Valid Score: 6.443\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 6.443 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 20.305 | Valid Score: 6.302\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 6.302 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 19.228 | Valid Score: 6.156\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 6.156 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 19.506 | Valid Score: 6.003\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 6.003 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 17.179 | Valid Score: 5.836\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 5.836 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 16.175 | Valid Score: 5.683\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 5.683 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 15.553 | Valid Score: 5.526\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 5.526 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 14.444 | Valid Score: 5.373\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 5.373 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 14.319 | Valid Score: 5.224\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 5.224 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 13.196 | Valid Score: 5.074\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 5.074 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 12.647 | Valid Score: 4.943\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 4.943 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 17.307 | Valid Score: 4.816\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 4.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 11.868 | Valid Score: 4.702\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 4.702 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 11.735 | Valid Score: 4.627\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 4.627 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 11.509 | Valid Score: 4.564\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 4.564 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 11.448 | Valid Score: 4.506\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 4.506 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 11.320 | Valid Score: 4.465\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 4.465 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 11.305 | Valid Score: 4.424\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 4.424 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 11.192 | Valid Score: 4.398\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 4.398 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 10.973 | Valid Score: 4.368\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 4.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 10.970 | Valid Score: 4.343\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 4.343 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 10.837 | Valid Score: 4.319\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 4.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 10.767 | Valid Score: 4.288\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 4.288 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 11.093 | Valid Score: 4.265\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 4.265 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 11.108 | Valid Score: 4.234\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 4.234 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 10.594 | Valid Score: 4.216\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 4.216 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 10.536 | Valid Score: 4.203\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 4.203 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 10.520 | Valid Score: 4.189\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 4.189 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 10.592 | Valid Score: 4.188\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 4.188 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 10.414 | Valid Score: 4.177\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 4.177 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 10.269 | Valid Score: 4.160\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 4.160 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 10.223 | Valid Score: 4.144\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 4.144 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 10.295 | Valid Score: 4.138\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 4.138 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 10.014 | Valid Score: 4.126\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 4.126 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 9.958 | Valid Score: 4.109\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 4.109 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 9.988 | Valid Score: 4.103\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 4.103 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 9.834 | Valid Score: 4.090\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 4.090 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 9.921 | Valid Score: 4.077\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 4.077 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 13.662 | Valid Score: 4.076\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 4.076 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 9.679 | Valid Score: 4.028\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 4.028 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 9.574 | Valid Score: 4.020\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 4.020 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 9.561 | Valid Score: 4.024\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 4.020 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 9.453 | Valid Score: 4.027\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 4.020 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 9.790 | Valid Score: 4.007\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 4.007 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 9.683 | Valid Score: 3.987\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 3.987 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 9.328 | Valid Score: 3.996\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.987 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 48/100 | Training Loss: 9.192 | Valid Score: 3.991\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.987 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 9.215 | Valid Score: 3.970\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.970 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 9.086 | Valid Score: 3.976\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.970 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 9.702 | Valid Score: 3.959\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.959 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 9.083 | Valid Score: 3.932\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.932 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 9.001 | Valid Score: 3.927\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.927 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 8.886 | Valid Score: 3.921\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.921 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 8.817 | Valid Score: 3.917\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.917 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 8.764 | Valid Score: 3.901\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.901 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 8.881 | Valid Score: 3.912\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.901 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 8.724 | Valid Score: 3.902\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.901 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 8.646 | Valid Score: 3.907\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.901 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 8.652 | Valid Score: 3.894\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 3.894 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 8.861 | Valid Score: 3.883\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 3.883 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 12.220 | Valid Score: 3.863\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 3.863 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 8.449 | Valid Score: 3.834\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 3.834 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 8.509 | Valid Score: 3.824\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 3.824 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 8.507 | Valid Score: 3.843\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 3.824 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 8.426 | Valid Score: 3.821\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 3.821 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 8.300 | Valid Score: 3.813\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 3.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 8.383 | Valid Score: 3.803\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 8.349 | Valid Score: 3.807\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 8.118 | Valid Score: 3.817\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 71/100 | Training Loss: 8.049 | Valid Score: 3.816\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 72/100 | Training Loss: 8.001 | Valid Score: 3.814\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 73/100 | Training Loss: 8.093 | Valid Score: 3.806\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 3.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 8.018 | Valid Score: 3.795\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 7.943 | Valid Score: 3.798\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 76/100 | Training Loss: 8.069 | Valid Score: 3.796\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 3.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 7.782 | Valid Score: 3.787\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 3.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 7.744 | Valid Score: 3.782\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 3.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 8.430 | Valid Score: 3.777\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 3.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 7.699 | Valid Score: 3.750\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 7.628 | Valid Score: 3.759\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 82/100 | Training Loss: 7.984 | Valid Score: 3.760\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 83/100 | Training Loss: 7.635 | Valid Score: 3.778\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 84/100 | Training Loss: 7.511 | Valid Score: 3.759\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 85/100 | Training Loss: 7.507 | Valid Score: 3.759\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 86/100 | Training Loss: 7.448 | Valid Score: 3.754\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 3.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 7.485 | Valid Score: 3.749\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 7.419 | Valid Score: 3.755\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 89/100 | Training Loss: 7.367 | Valid Score: 3.757\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 90/100 | Training Loss: 7.477 | Valid Score: 3.754\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 91/100 | Training Loss: 7.259 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 92/100 | Training Loss: 7.262 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 93/100 | Training Loss: 7.201 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 3.749 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 7.148 | Valid Score: 3.736\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 3.736 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 7.186 | Valid Score: 3.735\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 3.735 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 7.256 | Valid Score: 3.737\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 3.735 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 7.179 | Valid Score: 3.731\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 3.731 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 7.437 | Valid Score: 3.724\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 3.724 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 99/100 | Training Loss: 10.685 | Valid Score: 3.724\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 3.724 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 6.942 | Valid Score: 3.722\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 3.722 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.722 \n",
            "\n",
            "Test Score: 3.378 \n",
            "\n",
            "Execution time: 67.431 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWJ85PLsxmDy"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = dgl.nn.pytorch.conv.GATConv(in_feats, hidden_feats, num_heads=8)\n",
        "        self.conv2 = dgl.nn.pytorch.conv.GATConv(hidden_feats * 8, out_feats, num_heads=1)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        h = self.conv1(g, x).flatten(1)\n",
        "        h = F.elu(h)\n",
        "        h = F.dropout(h, p=0.5, training=self.training)\n",
        "        h = self.conv2(g, h).mean(1)\n",
        "        return F.log_softmax(h, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRVaO1hUxu2n",
        "outputId": "dbc1a8c5-7b38-4b11-e904-c17ce7afd6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 24.548 | Valid Score: 6.799\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 6.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 23.064 | Valid Score: 6.634\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 6.634 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 21.647 | Valid Score: 6.465\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 6.465 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 20.328 | Valid Score: 6.298\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 6.298 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 19.083 | Valid Score: 6.124\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 6.124 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 20.732 | Valid Score: 5.944\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 5.944 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 16.708 | Valid Score: 5.757\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 5.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 15.893 | Valid Score: 5.583\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 5.583 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 14.866 | Valid Score: 5.416\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 5.416 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 14.184 | Valid Score: 5.247\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 5.247 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 13.641 | Valid Score: 5.089\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 5.089 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 12.657 | Valid Score: 4.968\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 4.968 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 12.648 | Valid Score: 4.845\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 4.845 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 11.848 | Valid Score: 4.730\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 4.730 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 11.574 | Valid Score: 4.629\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 4.629 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 11.367 | Valid Score: 4.548\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 4.548 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 11.152 | Valid Score: 4.473\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 4.473 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 11.081 | Valid Score: 4.414\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 4.414 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 10.931 | Valid Score: 4.366\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 4.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 13.057 | Valid Score: 4.311\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 4.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 10.712 | Valid Score: 4.251\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 4.251 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 11.442 | Valid Score: 4.231\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 4.231 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 10.508 | Valid Score: 4.188\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 4.188 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 10.418 | Valid Score: 4.181\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 4.181 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 10.361 | Valid Score: 4.170\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 4.170 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 10.478 | Valid Score: 4.151\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 4.151 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 10.759 | Valid Score: 4.149\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 4.149 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 10.135 | Valid Score: 4.142\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 4.142 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 10.671 | Valid Score: 4.121\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 4.121 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 10.130 | Valid Score: 4.112\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 4.112 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 10.115 | Valid Score: 4.098\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 4.098 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 9.960 | Valid Score: 4.101\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 4.098 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 9.892 | Valid Score: 4.094\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 4.094 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 10.423 | Valid Score: 4.089\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 4.089 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 9.706 | Valid Score: 4.087\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 4.087 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 9.872 | Valid Score: 4.053\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 4.053 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 10.526 | Valid Score: 4.058\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 4.053 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 9.455 | Valid Score: 4.020\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 4.020 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 9.400 | Valid Score: 4.006\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 4.006 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 9.393 | Valid Score: 4.001\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 4.001 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 9.272 | Valid Score: 3.976\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 3.976 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 9.510 | Valid Score: 3.974\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 3.974 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 9.251 | Valid Score: 3.946\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 3.946 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 9.132 | Valid Score: 3.934\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 3.934 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 9.021 | Valid Score: 3.932\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 3.932 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 9.535 | Valid Score: 3.937\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 3.932 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 8.925 | Valid Score: 3.958\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 3.932 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 48/100 | Training Loss: 8.862 | Valid Score: 3.943\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 3.932 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 9.053 | Valid Score: 3.928\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 3.928 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 8.844 | Valid Score: 3.933\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 3.928 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 9.220 | Valid Score: 3.924\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 3.924 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 8.767 | Valid Score: 3.908\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 3.908 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 11.072 | Valid Score: 3.893\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 3.893 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 8.598 | Valid Score: 3.858\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 3.858 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 8.564 | Valid Score: 3.852\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 3.852 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 8.465 | Valid Score: 3.858\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 3.852 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 8.514 | Valid Score: 3.853\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 3.852 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 58/100 | Training Loss: 8.455 | Valid Score: 3.865\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 3.852 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 59/100 | Training Loss: 8.314 | Valid Score: 3.856\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 3.852 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 8.277 | Valid Score: 3.847\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 3.847 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 9.023 | Valid Score: 3.841\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 3.841 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 8.543 | Valid Score: 3.844\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 3.841 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 8.166 | Valid Score: 3.822\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 3.822 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 8.113 | Valid Score: 3.828\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 3.822 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 8.032 | Valid Score: 3.812\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 3.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 8.036 | Valid Score: 3.809\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 3.809 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 7.975 | Valid Score: 3.810\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 3.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 7.892 | Valid Score: 3.802\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 3.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 7.866 | Valid Score: 3.797\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 3.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 8.049 | Valid Score: 3.786\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 3.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 7.760 | Valid Score: 3.785\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 3.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 7.780 | Valid Score: 3.780\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 3.780 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 7.684 | Valid Score: 3.776\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 3.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 7.640 | Valid Score: 3.774\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 3.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 8.177 | Valid Score: 3.774\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 3.774 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 7.574 | Valid Score: 3.791\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 3.774 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 7.523 | Valid Score: 3.774\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 3.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 7.547 | Valid Score: 3.770\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 3.770 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 7.660 | Valid Score: 3.769\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 3.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 7.628 | Valid Score: 3.779\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 3.769 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 81/100 | Training Loss: 7.485 | Valid Score: 3.785\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 3.769 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 82/100 | Training Loss: 7.401 | Valid Score: 3.779\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 3.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 7.303 | Valid Score: 3.761\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 3.761 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 7.293 | Valid Score: 3.763\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 3.761 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 7.229 | Valid Score: 3.762\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 3.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 7.262 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 7.320 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 7.277 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 3.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 7.081 | Valid Score: 3.746\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 7.168 | Valid Score: 3.754\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 7.027 | Valid Score: 3.757\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 92/100 | Training Loss: 7.034 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 93/100 | Training Loss: 6.948 | Valid Score: 3.752\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 94/100 | Training Loss: 6.918 | Valid Score: 3.757\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 95/100 | Training Loss: 6.893 | Valid Score: 3.756\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 96/100 | Training Loss: 6.925 | Valid Score: 3.758\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 97/100 | Training Loss: 6.820 | Valid Score: 3.762\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 98/100 | Training Loss: 6.832 | Valid Score: 3.753\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 99/100 | Training Loss: 6.799 | Valid Score: 3.757\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 3.746 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 3.746 \n",
            "\n",
            "Test Score: 3.382 \n",
            "\n",
            "Execution time: 68.461 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
